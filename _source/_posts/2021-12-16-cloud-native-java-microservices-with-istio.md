---
layout: blog_post
title: "Build Cloud Native Java Microservices with a Service Mesh on Google Cloud"
author: deepu-sasidharan
by: advocate
communities: [devops, kubernetes, java, javascript]
description: "Build a OIDC secured cloud native Java microservice stack on Google Kubernetes Engine using Istio and JHipster"
tags: [kubernetes, jhipster, spring-boot, spring, java, oidc, istio, gcp, react, service-mesh]
tweets:
  - "Build a secure #Java microservice stack on Google Cloud using #JHipster, #Istio and #Kubernetes"
  - "Deploy a Cloud native #Java microservice stack to GKE with #Istio and #JHipster"
image:
type: conversion
---

Microservices are not everyone's cup of tea and it shouldn't be. Not every problem can be or should be solved by microservices. Sometimes building simple monoliths are far better options. Microservices are solutions for use cases where scale and scalability are important. We have been building microservices for a while now, though few years ago microservices where all the rage, made popular especially by companies like Netflix, Spotify, Google and so on. While the hype has died down a bit the genuine use cases still exist and with the advances in cloud computing technologies, building microservices as cloud native services is the way to go due to many of its benefits.

Today we will look at building a cloud native Java microservice stack that utilizes a service mesh to provide most of the distributed system needs and will deploy it to the cloud using Kubernetes.

So here is what we will be doing today:

- Build a Java microservice stack using JHipster, Spring Boot and Spring Cloud
- Configure to use Okta as the OAuth2 provider
- Create a Google Kubernetes Engine (GKE) cluster
- Deploy Istio service mesh to the cluster
- Setup monitoring and observability
- Deploy and monitor the microservices to the cluster

Let's get started!

{% include toc.md %}

**Pre-requisites**

- A [Google Cloud Platform](https://cloud.google.com/) account
- An Okta account. You can sign up for a [free Okta account](https://developer.okta.com/signup/). Or, you can use the [Keycloak](https://www.keycloak.org/) setup generated by JHipster.
- [Docker](https://www.docker.com/get-started) and [Docker Compose](https://docs.docker.com/compose/install/) installed on your machine
- [Node.js](https://nodejs.org/en/) installed on your machine
- [JHipster installed](https://www.jhipster.tech/installation/) on your machine
- [Google Cloud SDK](https://cloud.google.com/sdk/docs/install) installed and configured on your machine
- Basic understanding of Java, Spring, Containers and Kubernetes

## Why Build Cloud Native Microservices Using a Service Mesh?

Before we dive into building a cloud native microservice stack, let's take a look at what a service mesh is and what are the benefits of using one.

A service mesh provides features to help with common distributed microservice challenges. Like service discovery, routing, load balancing and so on. Today we will be using [Istio](https://istio.io/), one of the most popular service mesh solutions available. Istio is tailored for distributed application architectures, especially the ones that you might run in Kubernetes. Istio plays extremely nice with Kubernetes, so nice that you might think that it's part of the Kubernetes platform itself. Istio isn't the only service mesh around, we also have platforms like [Linkerd](https://linkerd.io/) and [Consul](https://www.consul.io/) which are also quite popular.

Istio specifically provides the following features.

- Secure service-to-service communication over TLS. Of course with support for identity based authentication and authorization.
- Service discovery, so that your microservices can discover each other
- Automatic load balancing for the services
- Traffic control features like routing, circuit breaking, retries, fail-overs and fault injection.
- A pluggable policy layer that can enforce stuff like access control, rate limiting, A/B testing, traffic splits, quotas and so on.
- It also provides automatic metrics, logs, and traces for all traffic within the cluster from Ingres to Egress and between pods.

### What is Istio Service Mesh?

Let's take a quick look at Istio internals. The Istio architecture can be classified into 2 distinct planes.

{% img blog/cloud-native-java-microservices-with-istio/istio-architecture.png alt:"Istio Service Mesh Architecture" width:"900" %}{: .center-image }

**Data plane**: It's made of [Envoy](https://www.envoyproxy.io/) proxies deployed as sidecars to our application containers. Envoy is a high performance, lightweight distributed proxy. It controls all the incoming and outgoing traffic to the container its attached to.

**Control plane**: It consists of the istiod demon and takes care of managing and configuring the envoy proxies to route traffic. It also enforces policies and collects telemetry. It has components like Pilot for traffic management, Citadel to manage security, and Galley to manage configurations.

We can use tools like [Grafana](https://grafana.com/), [Prometheus](https://prometheus.io/), [Kiali](https://www.kiali.io/) and [Zipkin](https://zipkin.io/) for Monitoring and Observability as they work well with the telemetry provided by Istio. You can use this or use your existing monitoring stack as well.

## Build a Java Microservices Stack using JHipster

Before you proceed, ensure you have installed JHipster. If not install it using the command `npm -g install generator-jhipster`. At the moment of writing i'm using the JHipster version **7.4.0**

We will be using the [JHipster Domain Language (JDL)](https://www.jhipster.tech/jdl/intro) to define our microservices, entities and deployment options. But first, lets take a look at the architecture we will be building today.

{% img blog/cloud-native-java-microservices-with-istio/istio-ms-architecture.png alt:"Istio Microservice Architecture" width:"900" %}{: .center-image }

We have the Istio control plane taking care of policy, load balancing and so on. We also have the Istio Ingress gateway that will route all external traffic to our applications. We have 4 microservices. First is a gateway application created by JHipster that acts as our React GUI and authentication layer. The remaining are services that provides APIs. Each of our containers will have an envoy proxy as a sidecar that is auto injected. We hook up Grafana, Prometheus, Zipkin and Kiali to the telemetry provided by Istio so that we have monitoring and observability for our cluster.
Each microservice also has its own database.

Its not an overly complex architecture but it's also not that simple. First, let us define our microservice using JDL. Create a file called **app.jdl** and paste the following content.

```kotlin
application {
  config {
    baseName store
    applicationType gateway
    packageName com.okta.developer.store
    serviceDiscoveryType no
    authenticationType oauth2
    prodDatabaseType postgresql
    cacheProvider hazelcast
    buildTool gradle
    clientFramework react
  }
  entities *
}


application {
  config {
    baseName product
    applicationType microservice
    packageName com.okta.developer.product
    serviceDiscoveryType no
    authenticationType oauth2
    prodDatabaseType postgresql
    cacheProvider hazelcast
    buildTool gradle
    serverPort 8081
  }
  entities Product, ProductCategory, ProductOrder, OrderItem
}

application {
  config {
    baseName invoice
    applicationType microservice
    packageName com.okta.developer.invoice
    serviceDiscoveryType no
    authenticationType oauth2
    prodDatabaseType postgresql
    buildTool gradle
    serverPort 8082
  }
  entities Invoice, Shipment
}

application {
  config {
    baseName notification
    applicationType microservice
    packageName com.okta.developer.notification
    serviceDiscoveryType no
    authenticationType oauth2
    databaseType mongodb
    cacheProvider no
    enableHibernateCache false
    buildTool gradle
    serverPort 8083
  }
  entities Notification
}
```

It's quite straightforward. Each application defines its name, package name, authentication type, database and so on. Please refer to the [JDL applications documentation](https://www.jhipster.tech/jdl/applications) for all supported options and configurations. Each application also defines the `applicationType` and the entities it serves. So next step would be to add these entities.

```kotlin
/**
 * Entities for Store Gateway
 */
// Customer for the store
entity Customer {
    firstName String required
    lastName String required
    gender Gender required
    email String required pattern(/^[^@\s]+@[^@\s]+\.[^@\s]+$/)
    phone String required
    addressLine1 String required
    addressLine2 String
    city String required
    country String required
}

enum Gender {
    MALE, FEMALE, OTHER
}

relationship OneToOne {
    Customer{user(login) required} to User
}

service Customer with serviceClass
paginate Customer with pagination

/**
 * Entities for product microservice
 */
// Product sold by the Online store
entity Product {
    name String required
    description String
    price BigDecimal required min(0)
    itemSize Size required
    image ImageBlob
}

enum Size {
    S, M, L, XL, XXL
}

entity ProductCategory {
    name String required
    description String
}

entity ProductOrder {
    placedDate Instant required
    status OrderStatus required
    code String required
    invoiceId Long
    customer String required
}

enum OrderStatus {
    COMPLETED, PENDING, CANCELLED
}

entity OrderItem {
    quantity Integer required min(0)
    totalPrice BigDecimal required min(0)
    status OrderItemStatus required
}

enum OrderItemStatus {
    AVAILABLE, OUT_OF_STOCK, BACK_ORDER
}

relationship ManyToOne {
	OrderItem{product(name) required} to Product
}

relationship OneToMany {
   ProductOrder{orderItem} to OrderItem{order(code) required} ,
   ProductCategory{product} to Product{productCategory(name)}
}

service Product, ProductCategory, ProductOrder, OrderItem with serviceClass
paginate Product, ProductOrder, OrderItem with pagination
microservice Product, ProductOrder, ProductCategory, OrderItem with product

/**
 * Entities for Invoice microservice
 */
// Invoice for sales
entity Invoice {
    code String required
    date Instant required
    details String
    status InvoiceStatus required
    paymentMethod PaymentMethod required
    paymentDate Instant required
    paymentAmount BigDecimal required
}

enum InvoiceStatus {
    PAID, ISSUED, CANCELLED
}

entity Shipment {
    trackingCode String
    date Instant required
    details String
}

enum PaymentMethod {
    CREDIT_CARD, CASH_ON_DELIVERY, PAYPAL
}

relationship OneToMany {
    Invoice{shipment} to Shipment{invoice(code) required}
}

service Invoice, Shipment with serviceClass
paginate Invoice, Shipment with pagination
microservice Invoice, Shipment with invoice

/**
 * Entities for notification microservice
 */
entity Notification {
    date Instant required
    details String
    sentDate Instant required
    format NotificationType required
    userId Long required
    productId Long required
}

enum NotificationType {
    EMAIL, SMS, PARCEL
}

microservice Notification with notification
```

We define entities for each service and mark the entities as microservice entities. We also define relationships between entities, enums and other options like pagination, service layer and so on. Please refer to JDL [Entities](https://www.jhipster.tech/jdl/entities-fields) and [relationships](https://www.jhipster.tech/jdl/relationships) documentation for more possibilities.

Now, we are ready to run JHipster. Open a terminal window on the folder where you saved the JDL and run the below command.

```bash
$ jhipster jdl app.jdl --fork
```

This will create the applications with all its entities and specified configurations. You should be able to see the gateway application in action by running the below command on the **store** folder. You will be redirected to Keycloak for login.

```bash
$ docker-compose -f src/main/docker/keycloak.yml up -d # starts keycloak in daemon mode
$ ./gradlew # starts the spring boot application
```

You can find a [sample application on GitHub](https://github.com/oktadev/okta-java-spring-k8s-istio-microservices-example).

## Configure Okta as Identity Provider

The applications are configured by default to use Keycloak as the identity provider since we choose OAuth2 as authentication mechanism. However, you can switch to any other OAuth2 provider by editing the **application.yml** file for each of the applications.

Let's see how to configure Okta as the identity provider. You may wonder? Why Okta? Keycloak is great for development and testing but its not robust for production as you would need to manage it and keep it updated and so on. Okta on the other hand lets you worry about your business needs by keeping your identity requirements always on and secure.

### Create an Okta application

{% include setup/cli.md type="jhipster" %}

### Configure OpenID Connect settings to use Okta

Open `src/main/resources/config/application.yml` file for each application and update `issuer-uri`, `client-id` and `client-secret` under the `spring.security.oauth2.client` section as shown below with values you obtained during previous step.

```yml
spring:
  ...
  security:
    oauth2:
      client:
        provider:
          oidc:
            issuer-uri: https://{yourOktaDomain}/oauth2/default
        registration:
          oidc:
            client-id: {yourClientId}
            client-secret:
            scope: openid,profile,email
```

> **Note**: For security reasons we will not set the client-secret on this file and instead use environment variable, `SPRING_SECURITY_OAUTH2_CLIENT_REGISTRATION_OIDC_CLIENT_SECRET` or Kubernetes secrets. You can also skip updating the application.yml files altogether and use environment variable or Kubernetes secrets for all the OIDC configurations.

You can run `./gradlew` on the store application to test the Okta login. Make sure to set the client secret environment variable first.

## Create a GKE Cluster and Install Istio

In order to deploy the stack to Google Kubernetes Engine, we need to create a cluster and install Istio. So lets begin by creating a cluster using Google CLoud SDK.

### Create a cluster

Make sure you are logged into the gcloud CLI and run the below command to create a GKE cluster.

```bash
# set region and zone
$ gcloud config set compute/region europe-west1
$ gcloud config set compute/zone europe-west1-b
# Create a project and enable container APIs
$ gcloud projects create jhipster-demo # You need to also enable billing via GUI
$ gcloud config set project jhipster-demo
$ gcloud services enable container.googleapis.com

# Create GKE Cluster
$ gcloud container clusters create hello-hipster \
     --num-nodes 4 \
     --machine-type n1-standard-2
```

This could take anywhere between 5-15 minutes. `--machine-type` is important as we need more CPU than what is available in the default setup. Once the cluster is created it should be set automatically as the current Kubernetes context. You can verify that by running `kubectl config current-context`. IF the new cluster is not set as the current context, you can set it by running `gcloud container clusters get-credentials hello-hipster`.

{% img blog/cloud-native-java-microservices-with-istio/kdash-clusters.png alt:"GKE Cluster nodes" width:"900" %}{: .center-image }

> **Note**: I'm using [KDash](https://kdash.cli.rs/) to monitor the cluster, you can try it or use kubectl, [k9s](https://github.com/derailed/k9s) and so on as you prefer.

### Install Istio to cluster

As of writing this, i'm using Istio version 1.12.1. You can install **istioctl** by running the below command, preferably from the home directory.

```bash
$ export ISTIO_VERSION=1.12.1
$ curl -L https://istio.io/downloadIstio | sh -
$ cd istio-$ISTIO_VERSION
$ export PATH=$PWD/bin:$PATH
```

You should now be able to run **istioctl** from the command line. Now, we can use the CLI to Install Istio to the GKE cluster. Istio provides few [Helm](https://helm.sh/) profiles out of the box, so for demo purposes i'll obviously use the demo profile. You can choose the production or dev profile as well. The command should install Istio and setup everything required on our cluster.

```bash
$ istioctl install --set profile=demo -y
```

> **Note**: If you run into any trouble with firewall or user privilege issues, please refer to [GKE setup guide from Istio](https://istio.io/latest/docs/setup/platform-setup/gke/).

Once the installation is complete, we would need to fetch the External IP of the Istio Ingress Gateway. If you are using KDash, you can see it on the services tab or you can run this command to get it using kubectl: `kubectl get svc istio-ingressgateway -n istio-system`

### Install Observability tools

Istio also provides addons for most of the popular monitoring and observability tools. Lets install Grafana, Prometheus, Kiali and Zipkin on our cluster. These are preconfigured to work with the telemetry data provided by Istio. Make sure you are in the folder where you installed Istio, like **istio-1.12.1**.

```bash
$ cd istio-$ISTIO_VERSION
$ kubectl apply -f samples/addons/grafana.yaml
$ kubectl apply -f samples/addons/prometheus.yaml
$ kubectl apply -f samples/addons/kiali.yaml
$ kubectl apply -f samples/addons/extras/zipkin.yaml
```

{% img blog/cloud-native-java-microservices-with-istio/istio-pods.png alt:"GKE Cluster with Istio pods" width:"900" %}{: .center-image }

If we look at the istio-system namespace, we can see all the Istio components along with Grafana, Prometheus, Kiali and Zipkin running. You can also see this by running `kubectl get pods -n istio-system`.

## Deploy the microservice stack to GKE

Our cluster is ready and we have Istio installed. Now, we can deploy our microservice stack to the cluster. But before that we need to create Kubernetes manifests for our deployments and services and configurations for Istio. And once again JHipster comes to the rescue. We can use the [JDL deployment](https://www.jhipster.tech/jdl/deployments) configurations to easily generate Kubernetes setup for our stack with one command.

### Create Kubernetes manifests

Create a new JDL file, say **deployment.jdl**, and add the following content to it.

```kotlin
// will be created under 'kubernetes' folder
deployment {
  deploymentType kubernetes
  appsFolders [store, invoice, notification, product]
  dockerRepositoryName "<your-docker-repository-name>"
  serviceDiscoveryType no
  istio true
  kubernetesServiceType Ingress
  kubernetesNamespace jhipster
  ingressDomain "<istio-ingress-gateway-external-ip>.nip.io"
  ingressType gke
}
```

I hope its self explanatory. You can refer the JDL deployment documentation for all the available options. We have enabled Istio and set the ingress domain to the external IP of the Istio Ingress Gateway that we notes earlier. Make sure to use a docker repo where you have push rights.

Now run the following command from the root folder where you ran the previous `jhipster jdl` command.

```bash
$ jhipster jdl deployment.jdl
```

This will create a new folder, **kubernetes**, with all the required Kubernetes manifests like deployments, services, Istio virtual services, gateways and so on for all the applications, databases, monitoring and so on.

{% img blog/cloud-native-java-microservices-with-istio/k8s-deployment.png alt:"JHipster JDL deployment" width:"900" %}{: .center-image }

As you can see, there is also a bunch of useful commands printed on the console that you can use to do the deployment.

### Update OIDC configuration

At this point we have everything ready, but since we didn't add the Okta OIDC client secret to the **application.yml** files, we need to add them as Kubernetes secrets. Under **kubernetes/store** folder add a new file names **okta-oidc-secrets.yml** with below content. You should ignore this file from GIT for security reasons.

```yml
apiVersion: v1
kind: Secret
metadata:
  name: okta-oidc
  namespace: jhipster
  labels:
    app: okta-oidc
type: Opaque
data:
  oidc-client-secret: <base64-of-your-okta-client-secret>
```

To get base64 of your client secret run the following command. The base64 command will be available if you have openssl installed.

```bash
$ echo -n "your-okta-client-secret" | base64
```

If you didn't add the client-id and issuer-url to the application.yml files, you can add them here or in the deployment spec below as they are not secrets.

Now open the **\*-deployment.yml** file in the **store**, **invoice**, **product** and **notification** folder and add the below to the **env** section of the **containers**.

```yml
- name: SPRING_SECURITY_OAUTH2_CLIENT_REGISTRATION_OIDC_CLIENT_SECRET
  valueFrom:
    secretKeyRef:
      name: okta-oidc
      key: oidc-client-secret
```

Here is the **kubernetes/store/store-deployment.yml** file with the change for reference.

```yml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: store
  namespace: jhipster
spec:
  ...
  template:
    ...
    spec:
      ...
      containers:
        - name: store-app
          image: deepu105/store
          env:
            - name: SPRING_PROFILES_ACTIVE
              value: prod
            ...
            - name: SPRING_SECURITY_OAUTH2_CLIENT_REGISTRATION_OIDC_CLIENT_SECRET
              valueFrom:
                secretKeyRef:
                  name: okta-oidc
                  key: oidc-client-secret
          resources:
            ...
```

### Deploy to GKE

We ready to deploy now. First, we need to build and push the images to the registry. For this we can use the handy [JIB](https://github.com/GoogleContainerTools/jib) commands provided by JHipster. Navigate to each of the microservice folder and run the command below.

```bash
$ cd store && ./gradlew bootJar -Pprod jib -Djib.to.image=deepu105/store
$ cd invoice && ./gradlew bootJar -Pprod jib -Djib.to.image=deepu105/invoice
$ cd notification && ./gradlew bootJar -Pprod jib -Djib.to.image=deepu105/notification
$ cd product && ./gradlew bootJar -Pprod jib -Djib.to.image=deepu105/product
```

Once the images are pushed to the docker registry, we can deploy the stack using the handy script provided by JHipster. Navigate to the kubernetes folder created by JHipster and run the following command.

```bash
$ cd kubernetes
$ ./kubectl-apply.sh -f
```

Once the deployments are done we need to wait for the pods to be in **RUNNING** status. Useful links will be printed on the terminal, make note of them.

{% img blog/cloud-native-java-microservices-with-istio/jhipster-deployment.png alt:"GKE cluster with application pods" width:"900" %}{: .center-image }

You can now access the application at the given `http://store.jhipster.<istio-ingress-gateway-external-ip>.nip.io` URI but you wont be able to login with Okta as we did not specify these URIs in the Okta OIDC application. Head over to the Okta admin console, `https://<your-okta-domain>.okta.com`, and navigate to **Applications** > **Applications** and open the application you created earlier. Edit the **General Settings** and add `http://store.jhipster.<istio-ingress-gateway-external-ip>.nip.io/login/oauth2/code/oidc` as **Sign-in redirect URI** and `http://store.jhipster.<istio-ingress-gateway-external-ip>.nip.io/` as **Sign-out redirect URI** and click **Save**.

{% img blog/cloud-native-java-microservices-with-istio/okta-update.png alt:"OKta OIDC app config update" width:"900" %}{: .center-image }

Now you can login with Okta. Play around with the application. Create entities and see the microservice in action.

{% img blog/cloud-native-java-microservices-with-istio/jh-store-app.png alt:"Store gateway application" width:"900" %}{: .center-image }

### Monitoring and observability

Since we deployed tools for observability, lets see what we have.

**Grafana**

First up is Grafana and Prometheus for metrics and dashboards. Click on the URI for Grafana from the previous deployment step. Click on **General** at the top left corner and click on the **istio** folder. You should see multiple pre-configured dashboards. You can find monitor performance of the workloads and the istio system itself here. You can also create your own dashboards if you like. The data visualized on Grafana is provided by Prometheus.

{% img blog/cloud-native-java-microservices-with-istio/grafana.png alt:"Grafana dashboard" width:"900" %}{: .center-image }

**Kiali**

<TODO>

{% img blog/cloud-native-java-microservices-with-istio/grafana.png alt:"Grafana dashboard" width:"900" %}{: .center-image }

**Zipkin**

<TODO>

{% img blog/cloud-native-java-microservices-with-istio/grafana.png alt:"Grafana dashboard" width:"900" %}{: .center-image }

### Cleanup

Once you are done with experiments, make sure to delete the cluster you created so that you don't end up with a big bill from Google. You can delete the cluster from the Google Cloud Console GUI or via the command line using the bel;ow command.

```bash
$ gcloud container clusters delete hello-hipster
```

## Learn more about Java Microservices, Istio, Kubernetes and JHipster

If you want to learn more about Kubernetes, OIDC, or using OIDC with Kubernetes, and security in general, check out these additional resources.

- [How to Secure Your Kubernetes Cluster with OpenID Connect and RBAC](/blog/2021/11/08/k8s-api-server-oidc)
- [Securing a Cluster](https://kubernetes.io/docs/tasks/administer-cluster/securing-a-cluster/)
- [OpenID Connect Tokens](https://kubernetes.io/docs/reference/access-authn-authz/authentication/#openid-connect-tokens)
- [RBAC vs. ABAC: Definitions & When to Use](https://www.okta.com/identity-101/role-based-access-control-vs-attribute-based-access-control/)
- [OAuth 2.0 and OpenID Connect Overview](https://developer.okta.com/docs/concepts/oauth-openid/)
- [Secure Access to AWS EKS Clusters for Admins](/blog/2021/10/08/secure-access-to-aws-eks)
- [Managing Multiple Okta Instances with Terraform Cloud](/blog/2020/02/03/managing-multiple-okta-instances-with-terraform-cloud)

Check the code out on [GitHub](https://github.com/oktadev/okta-java-spring-k8s-istio-microservices-example).

If you liked this tutorial, chances are you'll enjoy the others we publish. Please follow [@oktadev on Twitter](https://twitter.com/oktadev) and [subscribe to our YouTube channel](https://youtube.com/oktadev) to get notified when we publish new developer tutorials.
